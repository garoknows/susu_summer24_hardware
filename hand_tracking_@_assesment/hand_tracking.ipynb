{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Landmarks Definition: Landmarks are specific points identified on a hand. In MediaPipe's context, these are key points such as fingertips, knuckles, and the palm center.\n",
    "\n",
    "Coordinates: Each landmark is represented by its (x, y, z) coordinates:\n",
    "    - x and y: Coordinates within the image or frame, ranging from 0 to 1.0. They indicate the position in the frame.\n",
    "    - z: Depth coordinate, indicating how far the landmark is from the camera plane. This is provided as a floating-point value.\n",
    "\n",
    "Detection and Tracking: MediaPipe uses machine learning models to detect and track these landmarks in real-time. It leverages deep learning techniques to accurately identify the positions of these points across frames.\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# Initialize MediaPipe Hands\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=False,\n",
    "                       max_num_hands=2,\n",
    "                       min_detection_confidence=0.5,\n",
    "                       min_tracking_confidence=0.5)\n",
    "\n",
    "# Initialize MediaPipe Drawing\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Set the video source: 0 for webcam, or provide a video file path\n",
    "#video_source = \"C:/Users/MSI/Desktop/Untitled video.mp4\" # Use 0 for webcam, or provide a path to a video file\n",
    "#video_source = \"F:/gopro/cutter/0881/GOPR0881.MP4\"\n",
    "\n",
    "cap = cv2.VideoCapture(video_source)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(f\"Error: Could not open video source: {video_source}\")\n",
    "    exit()\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to capture frame from video source.\")\n",
    "        break\n",
    "\n",
    "    # Convert the BGR image to RGB\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the frame with MediaPipe Hands\n",
    "    result = hands.process(rgb_frame)\n",
    "\n",
    "    # Draw hand landmarks\n",
    "    if result.multi_hand_landmarks:\n",
    "        for hand_landmarks in result.multi_hand_landmarks:\n",
    "            # Print landmark coordinates\n",
    "            for idx, landmark in enumerate(hand_landmarks.landmark):\n",
    "                # Get landmark coordinates\n",
    "                landmark_x = int(landmark.x * frame.shape[1])\n",
    "                landmark_y = int(landmark.y * frame.shape[0])\n",
    "                landmark_z = landmark.z  # Z-coordinate (depth)\n",
    "\n",
    "                # Print coordinates of each landmark\n",
    "                print(f\"Landmark {idx}: ({landmark_x}, {landmark_y}, {landmark_z})\")\n",
    "\n",
    "                # Draw circles on the landmarks (optional)\n",
    "                cv2.circle(frame, (landmark_x, landmark_y), 5, (255, 0, 0), -1)\n",
    "\n",
    "            # Draw hand landmarks on the frame\n",
    "            mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('Hand Detection', frame)\n",
    "\n",
    "    # Exit on 'q' key press or window close\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q') or cv2.getWindowProperty('Hand Detection', cv2.WND_PROP_VISIBLE) < 1:\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "hands.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real-time hand detection using rtsp stream with mediapipe \n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "\n",
    "# Replace with your RTSP stream URL\n",
    "rtsp_url = \"rtsp://7vhK82:RiubbNyHyi9O@192.168.1.43:554/live/ch1\"\n",
    "\n",
    "# Initialize MediaPipe hands and drawing utilities\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Connect to the RTSP stream\n",
    "cap = cv2.VideoCapture(rtsp_url)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Unable to open video stream\")\n",
    "    exit()\n",
    "\n",
    "# Initialize variables for FPS calculation\n",
    "prev_frame_time = 0\n",
    "new_frame_time = 0\n",
    "\n",
    "with mp_hands.Hands(\n",
    "    min_detection_confidence=0.7,\n",
    "    min_tracking_confidence=0.7) as hands:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, image = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Unable to read frame\")\n",
    "            break\n",
    "\n",
    "        # Calculate FPS\n",
    "        new_frame_time = time.time()\n",
    "        fps = 1 / (new_frame_time - prev_frame_time)\n",
    "        prev_frame_time = new_frame_time\n",
    "\n",
    "        # Convert the FPS to an integer\n",
    "        fps = int(fps)\n",
    "\n",
    "        # Convert the frame rate to a string\n",
    "        fps_text = \"FPS: \" + str(fps)\n",
    "\n",
    "        # Flip the image horizontally for a later selfie-view display\n",
    "        # Convert the BGR image to RGB.\n",
    "        image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)\n",
    "        # To improve performance, optionally mark the image as not writeable to pass by reference.\n",
    "        image.flags.writeable = False\n",
    "        results = hands.process(image)\n",
    "\n",
    "        # Draw the hand annotations on the image.\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "        # Display the frame rate on the image\n",
    "        cv2.putText(image, fps_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "        cv2.putText(image, \"feed: 01\", (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Display the frame\n",
    "        cv2.imshow('RTSP Stream with MediaPipe Hands and FPS', image)\n",
    "\n",
    "        # Press 'q' to exit the loop\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
